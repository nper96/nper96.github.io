<html>
<head>
<title>Pattern marker example with Three.js</title>
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1">
<style>
html,body {
	margin: 0;
	padding: 0;
	width: 100%;
	text-align: center;
	overflow-x: hidden;
}
.portrait canvas {
	transform-origin: 0 0;
	transform: rotate(-90deg) translateX(-100%);
}
.desktop canvas {
 	transform: scale(-1, 1);
}
</style>
</head>
<body>

<h1>Pattern marker example with Three.js</h1>
<p>On Chrome on Android, tap the screen to start playing video stream.</p>
<p>Show  <a href="https://github.com/artoolkit/artoolkit5/blob/master/doc/patterns/Hiro%20pattern.pdf">Hiro pattern</a> and <a href="https://github.com/artoolkit/artoolkit5/blob/master/doc/patterns/Kanji%20pattern.pdf">Kanji pattern</a> to camera to display a colorful objects on top of them. Tap the screen to rotate the objects.

<p>Transformation Matrices: </p>
<p id="mtrxHiro"></p>
<p id="mtrxKanji"></p>

<p>&larr; <a href="index.html">Back to examples</a></p>

<script async src="artoolkit.min.js"></script>
<script async src="three.min.js"></script>
<script async src="artoolkit.three.js"></script>

<script>

window.ARThreeOnLoad = function() {

	ARController.getUserMediaThreeScene({maxARVideoSize: 320, cameraParam: 'Data/camera_para-iPhone 5 rear 640x480 1.0m.dat', 
	onSuccess: function(arScene, arController, arCamera) {

		document.body.className = arController.orientation;

		var renderer = new THREE.WebGLRenderer({antialias: true});
		if (arController.orientation === 'portrait') {
			var w = (window.innerWidth / arController.videoHeight) * arController.videoWidth;
			var h = window.innerWidth;
			renderer.setSize(w, h);
			renderer.domElement.style.paddingBottom = (w-h) + 'px';
		} else {
			if (/Android|mobile|iPad|iPhone/i.test(navigator.userAgent)) {
				renderer.setSize(window.innerWidth, (window.innerWidth / arController.videoWidth) * arController.videoHeight);
			} else {
				renderer.setSize(arController.videoWidth, arController.videoHeight);
				document.body.className += ' desktop';
			}
		}

		document.body.insertBefore(renderer.domElement, document.body.firstChild);
		
		// Detect barcode markers
		arController.setPatternDetectionMode(artoolkit.AR_MATRIX_CODE_DETECTION);

		// Process the video frame.
		arController.detectMarker(video);

		var markerMatrix = new Float32Array(12);
		var glMatrix = new Float32Array(16);

		// Get the number of markers from the ARController and iterate over each marker.
		var markers = arController.getMarkerNum();
		for (var i=0; i < markers.length; i++) {

			var marker = arController.getMarker(i);

			// If we found the number 5 marker, let's get its transform matrix.
			if (marker.idMatrix === 1) {
				arController.getTransMatSquare(i, 1 /* marker width */, markerMatrix);

				// And convert it to a WebGL matrix.
				arController.transMatToGLMat(markerMatrix, glMatrix);

				// Do something with the glMatrix ...
				console.log(glMatrix);

			}
		}

	delete window.ARThreeOnLoad;


};

if (window.ARController && ARController.getUserMediaThreeScene) {
	ARThreeOnLoad();
}
</script>

</body>
</html>